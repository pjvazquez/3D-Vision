{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import cv2                     # OpenCV library for computer vision\n",
    "from PIL import Image\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_img(img, h=1):\n",
    "    z = np.zeros_like(img)\n",
    "    for i in range(img.shape[1]-abs(h)):\n",
    "        if h >= 0:\n",
    "            z[:,i] = img[:,i+h]\n",
    "        else:\n",
    "            z[:,i+h] = img[:,i]\n",
    "        \n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift(xs, n):\n",
    "    if n == 0:\n",
    "        return xs\n",
    "    else:\n",
    "        e = np.zeros_like(xs)\n",
    "        if n >= 0:\n",
    "            e[:,n:] = xs[:,:-n]\n",
    "        else:\n",
    "            e[:,:n] = xs[:,-n:]\n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper function for image capturing from camera\n",
    "def take_frame():\n",
    "    # Create instance of video capturer\n",
    "    cv2.namedWindow(\"face detection activated\")\n",
    "    vc = cv2.VideoCapture(0)\n",
    "\n",
    "    # Try to get the first frame\n",
    "    if vc.isOpened(): \n",
    "        rval, frame = vc.read()\n",
    "        oldgray = None\n",
    "        print('Camera is opened \\n')\n",
    "    else:\n",
    "        rval = False\n",
    "        print('Camera is closed \\n')\n",
    "    \n",
    "    # Keep the video stream open\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "    gray = cv2.resize(gray, None,fx=0.5,fy=0.5)\n",
    "\n",
    "    height = gray.shape[0]\n",
    "    width = gray.shape[1]\n",
    "    half = int(width/2)\n",
    "\n",
    "    left_img = gray[:,:half]\n",
    "    right_img = gray[:,half:]\n",
    "\n",
    "    \n",
    "    return gray, left_img, right_img\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper function for image capturing from camera\n",
    "def laptop_camera_go():\n",
    "    # Create instance of video capturer\n",
    "    cv2.namedWindow(\"face detection activated\")\n",
    "    vc = cv2.VideoCapture(0)\n",
    "\n",
    "    # Try to get the first frame\n",
    "    if vc.isOpened(): \n",
    "        rval, frame = vc.read()\n",
    "        oldgray = None\n",
    "        print('Camera is opened \\n')\n",
    "    else:\n",
    "        rval = False\n",
    "        print('Camera is closed \\n')\n",
    "    \n",
    "    # Keep the video stream open\n",
    "    while rval:\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "        gray = cv2.resize(gray, None,fx=0.5,fy=0.5)\n",
    "        \n",
    "        height = gray.shape[0]\n",
    "        width = gray.shape[1]\n",
    "        half = int(width/2)\n",
    "        \n",
    "        left_img = gray[:,:half]\n",
    "        right_img = gray[:,half:]\n",
    "        \n",
    "        \n",
    "        # Plot the image from camera with all the face and eye detections marked\n",
    "        cv2.imshow(\"left image\", left_img)\n",
    "        cv2.imshow(\"right image\", right_img)\n",
    "        \n",
    "\n",
    "        if gray is not None:\n",
    "            s0 = left_img - right_img    \n",
    "            left_img_10 = desplaza_img(left_img, 10)\n",
    "            s10 = left_img_10 - right_img\n",
    "            cv2.imshow(\"s0\", s0)\n",
    "            cv2.imshow(\"left_img_10\", left_img_10)\n",
    "            cv2.imshow(\"s10\", s10)\n",
    "\n",
    "        # Press 'q' key to exit laptop video\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'): # Exit by pressing q key\n",
    "            # Destroy windows\n",
    "            cv2.destroyAllWindows()\n",
    "            \n",
    "            for i in range (1,5):\n",
    "                cv2.waitKey(1)\n",
    "            return\n",
    "            break\n",
    "        \n",
    "        # Read next frame\n",
    "        # control framerate for computation - default 20 frames per sec\n",
    "        time.sleep(0.1)\n",
    "        oldgray = gray\n",
    "        rval, frame = vc.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper function for image capturing from camera\n",
    "def show_capture():\n",
    "    # Create instance of video capturer\n",
    "    cv2.namedWindow(\"Real time image\")\n",
    "    vc = cv2.VideoCapture(0)\n",
    "\n",
    "    # Try to get the first frame\n",
    "    if vc.isOpened(): \n",
    "        rval, frame = vc.read()\n",
    "        oldgray = None\n",
    "        print('Camera is opened \\n')\n",
    "    else:\n",
    "        rval = False\n",
    "        print('Camera is closed \\n')\n",
    "    \n",
    "    # Keep the video stream open\n",
    "    while rval:\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "        gray = cv2.resize(gray, None,fx=0.5,fy=0.5)\n",
    "        \n",
    "        height = gray.shape[0]\n",
    "        width = gray.shape[1]\n",
    "        half = int(width/2)\n",
    "        \n",
    "        left_img = gray[:,:half]\n",
    "        right_img = gray[:,half:]\n",
    "        \n",
    "        \n",
    "        # Plot the image from camera with all the face and eye detections marked\n",
    "        cv2.imshow(\"left image\", left_img)\n",
    "\n",
    "    \n",
    "        # Press 'c' key to capture frame and exit laptop video\n",
    "        if cv2.waitKey(1) & 0xFF == ord('c'):\n",
    "            # Destroy windows\n",
    "            cv2.destroyAllWindows()\n",
    "            \n",
    "            for i in range (1,5):\n",
    "                cv2.waitKey(1)\n",
    "            return gray, left_img, right_img\n",
    "            break\n",
    "\n",
    "        # Press 'q' key to exit laptop video\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'): # Exit by pressing q key\n",
    "            # Destroy windows\n",
    "            cv2.destroyAllWindows()\n",
    "            \n",
    "            for i in range (1,5):\n",
    "                cv2.waitKey(1)\n",
    "            return\n",
    "            break\n",
    "        \n",
    "        # Read next frame\n",
    "        # control framerate for computation - default 20 frames per sec\n",
    "        time.sleep(0.1)\n",
    "        oldgray = gray\n",
    "        rval, frame = vc.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the laptop camera face/eye detector function above\n",
    "# laptop_camera_go()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, left, right = take_frame()\n",
    "plt.imshow(left)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(right)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(left-right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = left - right\n",
    "plt.imshow( diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desp = shift(left, 0)\n",
    "plt.imshow(desp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(200,200))\n",
    "num = 4\n",
    "step = 1\n",
    "num_imgs = 2*(num/step+1)\n",
    "for i in range(1, 5, step):\n",
    "    despp = shift(left, 10*i)\n",
    "    despn = shift(left, -10*i)\n",
    "    diffp = despp - right\n",
    "    diffn = despn - right\n",
    "    _, th_diffp = cv2.threshold(diffp, 0, 100, cv2.THRESH_BINARY)\n",
    "    _, th_diffn = cv2.threshold(diffn, 0, 100, cv2.THRESH_BINARY)\n",
    "    sub = fig.add_subplot(num_imgs,1,int(abs(i)*2+1) )\n",
    "    sub.imshow(th_diffp, cmap='gray')    \n",
    "    sub = fig.add_subplot(num_imgs,1,int(abs(i)*2+2) )\n",
    "    sub.imshow(th_diffn, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
